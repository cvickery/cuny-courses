#! /usr/local/bin/bash

# Run the sequence of sql and python scripts to re-create and update the cuny_courses database.

# Summary of recommendations from:
#    http://petereisentraut.blogspot.com/2010/03/running-sql-scripts-with-psql.html
#
# PGOPTIONS='--client-min-messages=warning' psql -X -q -a -1 -v ON_ERROR_STOP=1 --pset pager=off \
#            -d mydb -f dump.sql
#
#   --client-min-messages=warning to suppress NOTICE messages
#   -X suppress reading .psqlrc (where I set timing)
#   -f rather than < to get line numbers when a command fails
#   -q to suppress CREATE TABLE, etc messages
#   Others pertain more to restoring dump files, where a single transaction would make sense, and
#   are not used here.

(
  export PGOPTIONS='--client-min-messages=warning'
  export EVENTS_TABLE=events-dump_`date +'%F_%H:%M'`.sql

  # COMMAND LINE ARGUMENTS AND ENVIRONMENT VARIABLES
  # The update_db command normally runs with no arguments, but the normal process can be modified
  # to help manual recovery from abnormalities in the processes of running CUNYfirst queries and
  # transferring the resulting .CSV files to Tumbleweed.
  #
  # Dump and restore events table.
  #   The update process deletes all tables in the cuny_courses database and then rebuilds everything
  #   based on the information in the queries that ran on CUNYfirst. But the events table comes from
  #   user input in reviewing transfer rules, not CUNYfirst, so it can't be rebuilt from CUNYfirst
  #   data. Before dropping the db, the events table is dumped to a file, and then that file is
  #   restored near the end of the update process.
  #
  #   The NO_EVENTS environment variable, the -ne, or the --no-events command line option can be
  #   used to suppress the dump restore of the dumps table.
  #
  # Download queries from Tumbleweed.
  #   The dozen or so CUNYfirst queries that are used to build the database are saved as .CSV files
  #   and transferred to Tumbleweed by the CUNYfirst query scheduling system. The update process
  #   transfers these query files to the local system, deletest them from Tumbleweed, passes them
  #   through iconv to clean up text encoding issues, and saves them in the queries directory.
  #
  #   The SKIP_DOWNLOAD environment variable, the -sd, or the --skip-download command line option
  #   can be to skip the download from Tumbleweed, iconv, and move into queries steps.
  #
  # Check the integrity of the query files.
  #   Once the query files are in the queries folder, they are checked to be sure they are all,
  #   that they were all created on the same date, that they all have non-zero sizes, and that their
  #   sizes are within 10% of the sizes of the previous versions of the files. If all goes well,
  #   the file names are normalized (by dropping the CUNYfirst process id part of the file name),
  #   copied into the query_archives folder with their creation dates replacing their CUNYfirst
  #   process id in their file names, and moved into the latest_queries folder with their process
  #   ids removed for subsequent access by the update process steps to follow.
  #
  #   NO_SIZE_CHECK -ns --no-size-check
  #   NO_DATE_CHECK -nd --no-date-check
  #   NO_ARCHIVE -na --no-archive
  #   These three can be used to suppress their respective steps.
  #
  # Update registered programs.
  #   After the cuny_courses database update is finished, the table of academic programs registered
  #   with the NYS Department of Education (registered_programs) takes place.
  #
  #   NO_PROGRAMS -np --no-programs
  #   Suppress the registered_programs table update.

  # Environment variables
  for env_var in NO_EVENTS SKIP_DOWNLOAD NO_SIZE_CHECK NO_DATE_CHECK NO_ARCHIVE NO_PROGRAMS
  do
    if [[ `printenv` =~ $env_var ]]
    then export `echo $env_var | tr A-Z a-z`=1
    fi
  done

  # Command line arguments
  while [ $# -gt 0 ]
  do
    if [[ ( "$1" == "--no-events" ) || ( "$1" == "-ne" ) ]]
    then no_events=1
    elif [[ ( "$1" == "--skip-download") || ( "$1" == "-sd" ) ]]
      then skip_download=1
    elif [[ ( "$1" == "--no-size-check") || ( "$1" == "-ns" ) ]]
      then no_size_check=1
    elif [[ ( "$1" == "--no-size-check") || ( "$1" == "-ns" ) ]]
      then no_date_check=1
    elif [[ ( "$1" == "--no-archive") || ( "$1" == "-na" ) ]]
      then no_archive=1
    elif [[ ( "$1" == "--no-programs" ) || ( "$1" == "-np" ) ]]
      then no_programs=1
    else
      echo "Usage: $0 [-ne | --no-events] [-ns | --no-size-check] [-nd | --no-date-check]
       [-na | --no-archive] [-sd | --skip_download] [-np | --no_programs]"
      exit 1
    fi
    shift
  done

  # # Uncomment for debugging
  # for arg in no_events skip_download no_size_check no_date_check no_archive no_programs
  # do
  #   if [[ `printenv` =~ $arg ]]
  #   then echo $arg is set
  #   else echo $arg is not set
  #   fi
  # done

  echo BEGIN INITIALIZATION
  SECONDS=0

  # Try downloading new queries
  if [[ $skip_download != 1 ]]
  then
    echo -n "DOWNLOAD new query files... " | tee init.log
    /Users/vickery/bin/get_cuny
    if [[ $? -eq 1 ]]
    then  echo "No new query files. Use --skip-download to update anyway." | tee -a init.log
          exit 1
    fi
  fi

  # Python scripts process query results, so check that they are all present.
  # Report any mismatched dates, truncated or abnormally-sized queries and abort if not all a-ok

  echo -n "CHECK & ARCHIVE QUERY FILES... " | tee -a init.log
  args=''
  [[ $no_size_check == 1 ]] && args="$args -s"
  [[ $no_date_check == 1 ]] && args="$args -d"
  [[ $no_archive == 1 ]] && args="$args -a"
  ./check_queries.py $args > init.log
  if [ $? -ne 0 ]
    then echo "ERROR: mismatched query dates or sizes."
         exit 1
  fi

  # Enter update_db mode and give time for running queries to complete
  echo "START update_db mode" | tee -a init.log
  psql access_control -c \
        "update access_control set start_time = now() where event_type = 'update_db'"
  sleep 10

  # Save events table unless suppressed by command line
  if [[ $no_events != 1 && no_events != true ]]
  then
    echo -n SAVE events table to $EVENTS_TABLE ... | tee init_psql.log
    pg_dump --data-only --table=events -f $EVENTS_TABLE cuny_courses | tee -a init_psql.log
    if [[ $? -ne 0 ]]
      then  echo -e '\nFAILED!'
            psql access_control -c \
            "update access_control set start_time = NULL where event_type = 'update_db'"
            exit
    fi
    echo done. | tee -a init_psql.log
  fi

  # Kill any existing connections to the db
  echo -n "RESTART postgres ..." | tee -a init_psql.log
  brew services restart postgresql | tee -a init_psql.log
  echo -n "wait for postgres restart to complete ..." | tee -a init_psql.log
  sleep 10
  echo done. | tee -a init_psql.log
  # Do the drop
  echo -n "DROP cuny_courses... " | tee -a init_psql.log
  dropdb cuny_courses >> init_psql.log | tee -a init_psql.log
  if [[ $? -ne 0 ]]
    then  echo -e '\nFAILED!'
          psql access_control -c \
          "update access_control set start_time = NULL where event_type = 'update_db'"
          exit
  fi

  echo -n "CREATE cuny_courses... " | tee -a init_psql.log
  createdb cuny_courses >> init_psql.log
  if [[ $? -ne 0 ]]
    then echo -e '\nFAILED!'
         exit
  fi
  echo done. | tee -a init_psql.log

  echo -n "CREATE FUNCTION numeric_part... " | tee -a init_psql.log
  psql -X -q -d cuny_courses -f numeric_part.sql >> init_psql.log
  echo done. | tee -a init_psql.log

  echo -n "CREATE TABLE updates... " | tee -a init_psql.log
  psql -X -q -d cuny_courses -f updates.sql >> init_psql.log
  echo done. | tee -a init_psql.log

  # The following is the organizational structure of the University:
  #   Students are undergraduate or graduate (careers) at a college
  #   Colleges own divisions (groups/schools)
  #   Divisions own departments (organizations)
  #   Departments own disciplines (subjects)
  #   Disciplines map to CUNY subjects (external subject areas)
  #   Disciplines have courses
  #   Courses have a requirement designation
  #
  # The sequence of initializations, however, does not quite follow this
  # structure:
  #   Careers references institutions, so create institutions first
  #   Divisions references departments, so create departments first
  #
  echo -n "CREATE TABLE institutions... " | tee -a init_psql.log
  psql -X -q -d cuny_courses -f cuny_institutions.sql >> init_psql.log
  echo done. | tee -a init_psql.log

  echo -n "CREATE academic_programs... " | tee -a init_psql.log
  python3 populate_programs.py >> init.log
  if [[ $? -ne 0 ]]
    then echo -e '\nFAILED!'
         exit
  fi
  echo done. | tee -a init_psql.log

  # Now regenerate the tables that are based on query results
  #
  echo -n "CREATE TABLE cuny_careers... " | tee -a init.log
  python3 cuny_careers.py >> init.log
  if [ $? -ne 0 ]
    then echo -e '\nFAILED!'
         exit
  fi
  echo done. | tee -a init.log

  echo -n "CREATE TABLE cuny_departments... " | tee -a init.log
  python3 cuny_departments.py >> init.log
  if [ $? -ne 0 ]
    then echo  -e '\nFAILED!'
         exit
  fi
  echo done. | tee -a init.log

  echo -n "CREATE TABLE cuny_divisions... " | tee -a init.log
  python3 cuny_divisions.py --active_only >> init.log
  if [ $? -ne 0 ]
    then echo  -e '\nFAILED!'
         exit
  fi
  echo done. | tee -a init.log

  echo -n "CREATE TABLE cuny_subjects... " | tee -a init.log
  python3 cuny_subjects.py >> init.log
  if [ $? -ne 0 ]
    then echo  -e '\nFAILED!'
         exit
  fi
  echo done. | tee -a init.log

  echo -n "CREATE TABLE designations... " | tee -a init.log
  python3 designations.py >> init.log
  if [ $? -ne 0 ]
    then echo  -e '\nFAILED!'
         exit
  fi
  echo done. | tee -a init.log

  echo -n "CREATE TABLE crse_quiv_tbl... " | tee -a init.log
  python3 mk_crse_equiv_tbl.py >> init.log
  if [ $? -ne 0 ]
    then echo -e '\nFAILED!'
         exit
  fi
  echo done. | tee -a init.log

  echo -n "CREATE TABLE courses... " | tee -a init_psql.log
  psql -X -q -d cuny_courses -f create_courses.sql >> init_psql.log
  if [ $? -ne 0 ]
    then echo -e '\nFAILED!'
         exit
  fi
  psql -X -q -d cuny_courses -f view_courses.sql >> init_psql.log
  if [ $? -ne 0 ]
    then echo -e '\nFAILED!'
         exit
  fi
  echo done. | tee -a init_psql.log

  echo -n "POPULATE courses... " | tee -a init.log
  python3 populate_courses.py --progress >> init.log
  if [ $? -ne 0 ]
    then echo -e '\nFAILED!'
         exit
  fi
  echo done. | tee -a init.log

  echo -n "CHECK component contact hours... " | tee -a init.log
  python3 check_total_hours.py > check_contact_hours.log
  if [ $? -ne 0 ]
    then echo -e '\nFAILED!'
         exit
  fi
  echo done. | tee -a init.log

  # Transfer rules
  echo -n "CREATE TABLE review_status_bits... " | tee -a init_psql.log
  psql -X -q -d cuny_courses -f review_status_bits.sql >> init_psql.log
  if [ $? -ne 0 ]
    then echo -e '\nFAILED!'
         exit
  fi
  echo done. | tee -a init_psql.log

  echo -n "CREATE transfer_rules, source_courses, destination_courses... " | tee -a init_psql.log
  psql -X -q -d cuny_courses -f create_transfer_rules.sql >> init_psql.log
  psql -X -q -d cuny_courses -f view_transfer_rules.sql >> init_psql.log
  if [ $? -ne 0 ]
    then echo -e '\nFAILED!'
         exit
  fi
  echo done. | tee -a init_psql.log

  echo -n "POPULATE transfer_rules... " | tee -a init.log
  python3 populate_transfer_rules.py --progress --report >> init.log
  if [ $? -ne 0 ]
    then echo -e '\nFAILED!'
         exit
  fi
  echo done. | tee -a init.log

  echo -n "SPEEDUP transfer_rule lookups... " | tee -a init.log
  python3 mk_subject-rule_map.py --progress >> init.log
  if [ $? -ne 0 ]
    then echo -e '\nFAILED!'
         exit
  fi
  echo done. | tee -a init.log


  # The following takes too long, and doesn't really do more than
  # populate_transfer_rules.py already did. Historical Artifact.
  # echo -n "CHECK bogus rules... " | tee -a init.log
  # python3 bogus_rules.py --progress >> init.log
  # if [ $? -ne 0 ]
  #   then echo -e '\nFAILED!'
  #        exit
  # fi
  # echo done.

  # Managing the rule review process
  echo -n "CREATE TABLE sessions... " | tee -a init_psql.log
  psql -X -q -d cuny_courses -f sessions.sql >> init_psql.log
  if [ $? -ne 0 ]
    then echo -e '\nFAILED!'
         exit
  fi
  echo done. | tee -a init_psql.log

  #echo CREATE TABLE pending_reviews...
  #echo CREATE TABLE event_types...
  echo -n "CREATE TABLE events... " | tee -a init_psql.log
  psql -X -q -d cuny_courses -f reviews-events.sql >> init_psql.log
  if [ $? -ne 0 ]
    then echo -e '\nFAILED!'
         exit
  fi
  echo done. | tee -a init_psql.log

  if [[ $no_events -ne 1 ]]
  then
    echo -n "RESTORE previous events from $EVENTS_TABLE ... " | tee -a init_psql.log
    psql -X -q -d cuny_courses -f $EVENTS_TABLE >> init_psql.log
    if [ $? -ne 0 ]
      then echo -e '\nFAILED!'
           exit
    fi
    echo done. | tee -a init_psql.log
    echo ARCHIVE the events table.
    mv $EVENTS_TABLE ./event_dumps/

    echo -n "UPDATE review statuses... " | tee -a init.log
    python3 update_review_statuses.py >> init.log
    if [ $? -ne 0 ]
      then echo -e '\nFAILED!'
           exit
    fi
    echo done. | tee -a init.log
  fi

  echo -n "(Re-)Grant select access to view_only ROLE ..." | tee -a init_psql.log
  psql -X -q -d cuny_courses -f view_only_role.sql >> init_psql.log
  echo done. | tee -a init_psql.log

  # Exit update_db mode
  echo "END update_db mode" | tee -a init.log
  psql  access_control -c \
        "update access_control set start_time = NULL where event_type = 'update_db'"

  echo UPDATE COMPLETED in `gdate -d @"$SECONDS" +'%-Mm %-Ss'` | tee -a init.log

if [[ ! ( $no_programs == 1 || $no_programs == true ) ]]
then
  echo And now for the registered programs ...
  (
    cd /Users/vickery/registered_programs
    ./update_registered_programs.sh > registered_programs.log
  )
fi

)
